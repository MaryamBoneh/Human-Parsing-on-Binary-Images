{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Self-Correction-Human-Parsing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os, cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bQ45QDh5jf0q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Ninja"
      ],
      "metadata": {
        "id": "z5YZ9r5saZi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnuiyB88UYd9"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PeikeLi/Self-Correction-Human-Parsing.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Healthcare-Robotics/bodies-at-rest.git"
      ],
      "metadata": {
        "id": "777sqDd6hgRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Self-Correction-Human-Parsing-Segmented-Dataset\n",
        "!mkdir Self-Correction-Human-Parsing-Dataset"
      ],
      "metadata": {
        "id": "q8jfCufAACOd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Self-Correction-Human-Parsing"
      ],
      "metadata": {
        "id": "SuH2g2MaUdAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68d3331-8edf-411a-8383-1816d3348359"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Self-Correction-Human-Parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir input\n",
        "!mkdir output\n",
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "6EPnpRFNVMn2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/bodies-at-rest/PressurePose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjyFUwGiU_qp",
        "outputId": "b84f850b-580d-482f-ae95-41151de3a617"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bodies-at-rest/PressurePose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x download_real.sh\n",
        "!bash download_real.sh"
      ],
      "metadata": {
        "id": "focJqFhAiQoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object = pd.read_pickle(r'/content/bodies-at-rest/data_BR/real/S103/prescribed.p')\n",
        "print(len(object['RGB']))\n",
        "print(object['RGB'][0].shape)"
      ],
      "metadata": {
        "id": "3pkBlvug-2IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/bodies-at-rest/data_BR/real/\"\n",
        "folders = os.listdir(path)\n",
        "w, h = 880, 440\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "  object = pd.read_pickle(r'/content/bodies-at-rest/data_BR/real/'+ folder +'/prescribed.p')\n",
        "  for j in range(0, len(object['RGB'])):\n",
        "    rgb_img = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    rgb_img = object['RGB'][j]\n",
        "    rgb_img = Image.fromarray(rgb_img, 'RGB')\n",
        "    rgb_img.save(f'/content/Self-Correction-Human-Parsing-Dataset/{i}{j}.jpg')"
      ],
      "metadata": {
        "id": "1gkvbz8qyJx0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/Self-Correction-Human-Parsing/simple_extractor.py' --dataset 'pascal' --model-restore '/content/drive/MyDrive/models/exp-schp-201908270938-pascal-person-part.pth' --input-dir '/content/Self-Correction-Human-Parsing-Dataset/' --output-dir '/content/Self-Correction-Human-Parsing-Segmented-Dataset'"
      ],
      "metadata": {
        "id": "TVyPAveIW8nZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9faa724f-7dc3-4699-82cd-e7508d58e986"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating total class number 7 with ['Background', 'Head', 'Torso', 'Upper Arms', 'Lower Arms', 'Upper Legs', 'Lower Legs']\n",
            "100% 914/914 [03:53<00:00,  3.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/Self-Correction-Human-Parsing-Segmented-Dataset/\"\n",
        "segmented_images = os.listdir(path)\n",
        "\n",
        "len(segmented_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55EI5IImXP_s",
        "outputId": "c2524105-89ab-4ff0-b95e-cd0531394cc1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "914"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Self-Correction-Human-Parsing/dataset/\n",
        "!mkdir train_images\n",
        "!mkdir train_segmentation\n",
        "!mkdir val_images\n",
        "!mkdir val_segmentation"
      ],
      "metadata": {
        "id": "fSkjL6qfJVcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = open('train_id.txt', 'w')\n",
        "val_id = open('val_id.txt', 'w')\n",
        "\n",
        "for i ,image in enumerate(segmented_images):\n",
        "  img = cv2.imread(os.path.join(path, image))\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img_gray[img_gray > 0] = 255\n",
        "  img_gray[img_gray == 0] = 0\n",
        "  image_name = image.split('.')[0]\n",
        "  if i < 800:\n",
        "    cv2.imwrite(f\"train_images/{image_name}.JPG\", img_gray)\n",
        "    train_id.write(f\"{image_name}\")\n",
        "    train_id.write('\\n')\n",
        "  else:\n",
        "    cv2.imwrite(f\"val_images/{image_name}.JPG\", img_gray)\n",
        "    val_id.write(f\"{image_name}\")\n",
        "    val_id.write('\\n')\n",
        "\n",
        "train_id.close()\n",
        "val_id.close()"
      ],
      "metadata": {
        "id": "wyu-0U9dSCUT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/Self-Correction-Human-Parsing-Segmented-Dataset/\"\n",
        "segmented_images = os.listdir(path)\n",
        "\n",
        "for i, image in enumerate(segmented_images):\n",
        "  img_rgb = cv2.imread(os.path.join(path, image))\n",
        "  img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  img_gray[img_gray == 0] = 0\n",
        "  img_gray[img_gray == 15] = 1\n",
        "  img_gray[img_gray == 38] = 2\n",
        "  img_gray[img_gray == 53] = 3\n",
        "  img_gray[img_gray == 75] = 4\n",
        "  img_gray[img_gray == 90] = 5\n",
        "  img_gray[img_gray == 113] = 6\n",
        "\n",
        "  if i < 800:\n",
        "    cv2.imwrite(f\"train_segmentation/{image}\", img_gray)\n",
        "  else:\n",
        "    cv2.imwrite(f\"val_segmentation/{image}\", img_gray)"
      ],
      "metadata": {
        "id": "x-P87X4ibHoD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Self-Correction-Human-Parsing/\n",
        "!mkdir pretrain_model"
      ],
      "metadata": {
        "id": "BGe1yKSapal7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = \"http://sceneparsing.csail.mit.edu/model/pretrained_resnet/resnet101-imagenet.pth\"\n",
        "out = \"/content/Self-Correction-Human-Parsing/pretrain_model/resnet101-imagenet.pth\"\n",
        "gdown.download(url, out) "
      ],
      "metadata": {
        "id": "bAaGQ0oZyBqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python 'train.py' --batch-size 2 --data-dir 'dataset' --epochs 50 --num-classes 7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8FtT-Nsewdb",
        "outputId": "b738e050-79ff-4a24-e581-11fab23620e8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(arch='resnet101', batch_size=2, cycle_epochs=10, data_dir='dataset', epochs=50, eval_epochs=10, gpu='0,1,2', ignore_label=255, imagenet_pretrain='./pretrain_model/resnet101-imagenet.pth', input_size='473,473', lambda_c=0.1, lambda_e=1, lambda_s=1, learning_rate=0.007, log_dir='./log', model_restore='./log/checkpoint.pth.tar', momentum=0.9, num_classes=7, random_mirror=False, random_scale=False, schp_restore='./log/schp_checkpoint.pth.tar', schp_start=100, start_epoch=0, weight_decay=0.0005)\n",
            "image mean: [0.406, 0.456, 0.485]\n",
            "image std: [0.225, 0.224, 0.229]\n",
            "input space:BGR\n",
            "BGR Transformation\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Total training samples: 800\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "dataset/train_images/833.jpg\n",
            "dataset/train_images/818.jpg\n",
            "dataset/train_images/1027.jpg\n",
            "dataset/train_images/02.jpg\n",
            "dataset/train_images/1721.jpg\n",
            "dataset/train_images/1139.jpg\n",
            "dataset/train_images/013.jpg\n",
            "dataset/train_images/1837.jpg\n",
            "dataset/train_images/44.jpg\n",
            "dataset/train_images/1343.jpg\n",
            "dataset/train_images/1322.jpg\n",
            "dataset/train_images/1731.jpg\n",
            "dataset/train_images/627.jpg\n",
            "dataset/train_images/321.jpg\n",
            "dataset/train_images/724.jpg\n",
            "Traceback (most recent call last):\n",
            "dataset/train_images/1712.jpg\n",
            "dataset/train_images/58.jpg\n",
            "dataset/train_images/1238.jpg\n",
            "dataset/train_images/1330.jpg\n",
            "dataset/train_images/188.jpg\n",
            "dataset/train_images/210.jpg\n",
            "dataset/train_images/245.jpg\n",
            "dataset/train_images/421.jpg\n",
            "dataset/train_images/1323.jpg\n",
            "dataset/train_images/1511.jpg\n",
            "dataset/train_images/1340.jpg\n",
            "  File \"train.py\", line 231, in <module>\n",
            "dataset/train_images/1810.jpg\n",
            "dataset/train_images/1640.jpg\n",
            "dataset/train_images/183.jpg\n",
            "dataset/train_images/711.jpg\n",
            "    main()\n",
            "  File \"train.py\", line 168, in main\n",
            "    for i_iter, batch in enumerate(train_loader):\n",
            "dataset/train_images/924.jpg\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "dataset/train_images/1315.jpg\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "dataset/train_images/1930.jpg\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "AttributeError: Caught AttributeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/Self-Correction-Human-Parsing/datasets/datasets.py\", line 68, in __getitem__\n",
            "    h, w, _ = im.shape\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "\n"
          ]
        }
      ]
    }
  ]
}